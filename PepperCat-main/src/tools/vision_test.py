import cv2
import numpy as np
import mediapipe as mp
import time
import threading
import tkinter as tk
from tkinter import ttk, messagebox
from typing import Dict, Any, Optional
from src.openmanus_agent.tool_base import BaseTool
import os
import asyncio

class VisionTestWindow:
    """è§†åŠ›æ£€æµ‹çª—å£"""
    
    def __init__(self):
        self.window = None
        self.cap = None
        self.face_mesh = None
        self.hands = None
        self.testing = False
        self.result = None
        
        # æµ‹è¯•å‚æ•°
        self.current_size = 0.5
        self.current_direction = 0  # 0:å³, 90:ä¸‹, 180:å·¦, 270:ä¸Š
        self.correct_count = 0
        self.total_count = 0
        self.distance = 60
        self.test_start_time = None
        
        # è§†åŠ›æ ‡å‡†å¯¹ç…§è¡¨
        self.VISION_STANDARD = {
            0.1: 4.0, 0.15: 4.2, 0.2: 4.4,
            0.25: 4.6, 0.3: 4.8, 0.4: 5.0,
            0.5: 5.2, 0.6: 5.4, 0.8: 5.6,
            1.0: 5.8
        }
    
    def create_window(self):
        """åˆ›å»ºè§†åŠ›æ£€æµ‹çª—å£"""
        self.window = tk.Toplevel()
        self.window.title("è§†åŠ›æ£€æµ‹")
        self.window.geometry("800x600")
        self.window.resizable(False, False)
        
        # è®¾ç½®çª—å£æ ·å¼
        style = ttk.Style()
        style.theme_use('clam')
        
        # ä¸»å®¹å™¨
        main_frame = ttk.Frame(self.window, padding="20")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="è§†åŠ›æ£€æµ‹", font=('Arial', 18, 'bold'))
        title_label.grid(row=0, column=0, columnspan=2, pady=(0, 20))
        
        # è¯´æ˜æ–‡å­—
        instruction_label = ttk.Label(main_frame, 
            text="è¯·ä¿æŒè·ç¦»å±å¹•60å˜ç±³ï¼Œç”¨æ‰‹åŠ¿æŒ‡ç¤ºEå­—å¼€å£æ–¹å‘\n"
                 "æ‰‹åŠ¿è¯´æ˜ï¼š\n"
                 "ğŸ‘† é£ŸæŒ‡å‘ä¸Š = å‘ä¸Š\n"
                 "ğŸ‘‡ é£ŸæŒ‡å‘ä¸‹ = å‘ä¸‹\n"
                 "ğŸ‘ˆ é£ŸæŒ‡å‘å·¦ = å‘å·¦\n"
                 "ğŸ‘‰ é£ŸæŒ‡å‘å³ = å‘å³",
            font=('Arial', 12), justify=tk.LEFT)
        instruction_label.grid(row=1, column=0, columnspan=2, pady=(0, 20))
        
        # æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ
        self.camera_label = ttk.Label(main_frame, text="æ­£åœ¨å¯åŠ¨æ‘„åƒå¤´...", 
                                     font=('Arial', 14))
        self.camera_label.grid(row=2, column=0, columnspan=2, pady=(0, 20))
        
        # çŠ¶æ€ä¿¡æ¯
        self.status_label = ttk.Label(main_frame, text="å‡†å¤‡å¼€å§‹æ£€æµ‹", 
                                     font=('Arial', 12))
        self.status_label.grid(row=3, column=0, columnspan=2, pady=(0, 20))
        
        # æŒ‰é’®æ¡†æ¶
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=4, column=0, columnspan=2, pady=(0, 20))
        
        # å¼€å§‹æŒ‰é’®
        self.start_btn = ttk.Button(button_frame, text="å¼€å§‹æ£€æµ‹", 
                                   command=self.start_test)
        self.start_btn.pack(side=tk.LEFT, padx=5)
        
        # åœæ­¢æŒ‰é’®
        self.stop_btn = ttk.Button(button_frame, text="åœæ­¢æ£€æµ‹", 
                                  command=self.stop_test, state='disabled')
        self.stop_btn.pack(side=tk.LEFT, padx=5)
        
        # å…³é—­æŒ‰é’®
        close_btn = ttk.Button(button_frame, text="å…³é—­", 
                              command=self.close_window)
        close_btn.pack(side=tk.LEFT, padx=5)
        
        # ç»“æœæ˜¾ç¤º
        self.result_label = ttk.Label(main_frame, text="", 
                                     font=('Arial', 14, 'bold'))
        self.result_label.grid(row=5, column=0, columnspan=2, pady=(10, 0))
        
        # ç»‘å®šå…³é—­äº‹ä»¶
        self.window.protocol("WM_DELETE_WINDOW", self.close_window)
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.init_camera()
    
    def init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´å’Œæ£€æµ‹æ¨¡å‹"""
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                raise RuntimeError("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            # åˆå§‹åŒ–MediaPipe
            self.face_mesh = mp.solutions.face_mesh.FaceMesh(
                max_num_faces=1, refine_landmarks=True,
                min_detection_confidence=0.5, min_tracking_confidence=0.5
            )
            self.hands = mp.solutions.hands.Hands(
                min_detection_confidence=0.5, min_tracking_confidence=0.5
            )
            
            self.status_label.config(text="æ‘„åƒå¤´å·²å°±ç»ªï¼Œç‚¹å‡»å¼€å§‹æ£€æµ‹")
            
        except Exception as e:
            self.status_label.config(text=f"æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def start_test(self):
        """å¼€å§‹è§†åŠ›æ£€æµ‹"""
        if not self.cap or not self.cap.isOpened():
            messagebox.showerror("é”™è¯¯", "æ‘„åƒå¤´æœªå°±ç»ª")
            return
        
        self.testing = True
        self.test_start_time = time.time()
        self.correct_count = 0
        self.total_count = 0
        self.current_size = 0.5
        
        self.start_btn.config(state='disabled')
        self.stop_btn.config(state='normal')
        self.status_label.config(text="æ£€æµ‹è¿›è¡Œä¸­...")
        
        # å¯åŠ¨æ£€æµ‹çº¿ç¨‹
        self.test_thread = threading.Thread(target=self.run_test_loop, daemon=True)
        self.test_thread.start()
    
    def stop_test(self):
        """åœæ­¢è§†åŠ›æ£€æµ‹"""
        self.testing = False
        self.start_btn.config(state='normal')
        self.stop_btn.config(state='disabled')
        
        if self.total_count > 0:
            self.calculate_result()
    
    def run_test_loop(self):
        """è¿è¡Œæ£€æµ‹å¾ªç¯"""
        last_change_time = time.time()
        display_duration = 2.0  # Eå­—æ˜¾ç¤ºæ—¶é•¿
        
        while self.testing and self.total_count < 10:
            ret, frame = self.cap.read()
            if not ret:
                continue
            
            # å¤„ç†å¸§
            frame = cv2.flip(frame, 1)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # æ£€æµ‹é¢éƒ¨è·ç¦»
            face_results = self.face_mesh.process(rgb_frame)
            if face_results.multi_face_landmarks:
                self.distance = self.calculate_face_distance(
                    face_results.multi_face_landmarks[0]
                )
            
            # æ£€æµ‹æ‰‹åŠ¿
            hand_direction = None
            hand_results = self.hands.process(rgb_frame)
            if hand_results.multi_hand_landmarks:
                hand_direction = self.detect_hand_direction(
                    hand_results.multi_hand_landmarks[0]
                )
            
            # æ›´æ–°æ˜¾ç¤º
            self.update_display(frame)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†æ‰‹åŠ¿å“åº”
            if time.time() - last_change_time >= display_duration:
                if hand_direction is not None:
                    self.process_response(hand_direction)
                
                # æ›´æ–°Eå­—å‚æ•°
                self.update_e_parameters()
                last_change_time = time.time()
            
            # æ£€æŸ¥é€€å‡ºæ¡ä»¶
            if self.total_count >= 10 or self.correct_count >= 8:
                break
        
        # æ£€æµ‹ç»“æŸ
        self.window.after(0, self.stop_test)
    
    def calculate_face_distance(self, landmarks):
        """è®¡ç®—é¢éƒ¨è·ç¦»"""
        # ä½¿ç”¨é¢éƒ¨å…³é”®ç‚¹è®¡ç®—è·ç¦»
        nose = landmarks.landmark[1]  # é¼»å°–
        left_eye = landmarks.landmark[33]  # å·¦çœ¼
        right_eye = landmarks.landmark[263]  # å³çœ¼
        
        # è®¡ç®—çœ¼é—´è·
        eye_distance = np.sqrt(
            (left_eye.x - right_eye.x)**2 + 
            (left_eye.y - right_eye.y)**2
        )
        
        # æ ¹æ®çœ¼é—´è·ä¼°ç®—è·ç¦»ï¼ˆç»éªŒå…¬å¼ï¼‰
        distance = 60 / eye_distance if eye_distance > 0 else 60
        return max(30, min(100, distance))  # é™åˆ¶åœ¨30-100cmèŒƒå›´å†…
    
    def detect_hand_direction(self, landmarks):
        """æ£€æµ‹æ‰‹åŠ¿æ–¹å‘"""
        # è·å–é£ŸæŒ‡å…³é”®ç‚¹
        index_tip = landmarks.landmark[8]  # é£ŸæŒ‡å°–
        index_pip = landmarks.landmark[6]  # é£ŸæŒ‡ç¬¬äºŒå…³èŠ‚
        middle_tip = landmarks.landmark[12]  # ä¸­æŒ‡å°–
        
        # è®¡ç®—é£ŸæŒ‡æ–¹å‘
        dx = index_tip.x - index_pip.x
        dy = index_tip.y - index_pip.y
        
        # åˆ¤æ–­æ–¹å‘
        if abs(dx) > abs(dy):
            if dx > 0:
                return 0  # å³
            else:
                return 180  # å·¦
        else:
            if dy > 0:
                return 90  # ä¸‹
            else:
                return 270  # ä¸Š
    
    def process_response(self, detected_direction):
        """å¤„ç†æ‰‹åŠ¿å“åº”"""
        self.total_count += 1
        if detected_direction == self.current_direction:
            self.correct_count += 1
        
        # æ›´æ–°çŠ¶æ€
        accuracy = self.correct_count / self.total_count
        self.window.after(0, lambda: self.status_label.config(
            text=f"å‡†ç¡®ç‡: {accuracy:.1%} ({self.correct_count}/{self.total_count})"
        ))
    
    def update_e_parameters(self):
        """æ›´æ–°Eå­—å‚æ•°"""
        # æ ¹æ®å‡†ç¡®ç‡è°ƒæ•´å¤§å°
        if self.total_count > 0:
            accuracy = self.correct_count / self.total_count
            if accuracy > 0.8:
                self.current_size = max(0.1, self.current_size * 0.9)
            elif accuracy < 0.6:
                self.current_size = min(1.0, self.current_size * 1.1)
        
        # éšæœºæ”¹å˜æ–¹å‘
        self.current_direction = (self.current_direction + 90) % 360
    
    def update_display(self, frame):
        """æ›´æ–°æ˜¾ç¤ºå†…å®¹"""
        # ç”ŸæˆEå­—å›¾åƒ
        e_image = self.create_e_image()
        
        # è°ƒæ•´å¤§å°
        height, width = e_image.shape[:2]
        new_width = int(width * self.current_size)
        new_height = int(height * self.current_size)
        resized_e = cv2.resize(e_image, (new_width, new_height))
        
        # æ—‹è½¬Eå­—
        rotated_e = self.rotate_image(resized_e, self.current_direction)
        
        # åˆå¹¶åˆ°ç”»é¢ä¸­å¤®
        h, w = frame.shape[:2]
        e_h, e_w = rotated_e.shape[:2]
        x_offset = (w - e_w) // 2
        y_offset = (h - e_h) // 2
        
        # ç¡®ä¿ä¸è¶Šç•Œ
        if x_offset >= 0 and y_offset >= 0:
            for c in range(3):
                frame[y_offset:y_offset+e_h, x_offset:x_offset+e_w, c] = \
                    rotated_e[:, :, c] * (rotated_e[:, :, 3]/255.0) + \
                    frame[y_offset:y_offset+e_h, x_offset:x_offset+e_w, c] * (1.0 - rotated_e[:, :, 3]/255.0)
        
        # æ·»åŠ ä¿¡æ¯å åŠ 
        info_lines = [
            f"è§†åŠ›: {self.calculate_vision_level():.1f}",
            f"è·ç¦»: {self.distance:.0f}cm",
            f"å‡†ç¡®ç‡: {self.correct_count}/{self.total_count}",
            f"å½“å‰æ–¹å‘: {['å³', 'ä¸‹', 'å·¦', 'ä¸Š'][self.current_direction // 90]}"
        ]
        
        for i, text in enumerate(info_lines):
            cv2.putText(frame, text, (10, 30 + 30*i),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                       (0, 0, 255) if i == 0 else (255, 255, 255), 2)
        
        # è½¬æ¢ä¸ºTkinterå¯æ˜¾ç¤ºçš„æ ¼å¼
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        height, width, channel = frame_rgb.shape
        bytes_per_line = 3 * width
        
        # æ›´æ–°æ˜¾ç¤º
        try:
            from PIL import Image, ImageTk
            pil_image = Image.fromarray(frame_rgb)
            pil_image = pil_image.resize((400, 300), Image.Resampling.LANCZOS)
            tk_image = ImageTk.PhotoImage(pil_image)
            
            self.window.after(0, lambda: self.camera_label.config(image=tk_image))
            self.window.after(0, lambda: setattr(self.camera_label, 'image', tk_image))
        except ImportError:
            # å¦‚æœæ²¡æœ‰PILï¼Œæ˜¾ç¤ºæ–‡å­—
            self.window.after(0, lambda: self.camera_label.config(
                text=f"æ‘„åƒå¤´è¿è¡Œä¸­ - è§†åŠ›: {self.calculate_vision_level():.1f}"
            ))
    
    def create_e_image(self):
        """åˆ›å»ºEå­—å›¾åƒ"""
        # åˆ›å»ºé€æ˜èƒŒæ™¯
        img = np.zeros((200, 200, 4), dtype=np.uint8)
        img[:, :, 3] = 0  # é€æ˜é€šé“
        
        # ç»˜åˆ¶Eå­—
        color = (255, 255, 255, 255)  # ç™½è‰²
        thickness = 8
        
        # Eå­—çš„ä¸‰ä¸ªæ¨ªçº¿
        cv2.line(img, (50, 50), (150, 50), color, thickness)   # ä¸Šæ¨ªçº¿
        cv2.line(img, (50, 100), (150, 100), color, thickness) # ä¸­æ¨ªçº¿
        cv2.line(img, (50, 150), (150, 150), color, thickness) # ä¸‹æ¨ªçº¿
        cv2.line(img, (50, 50), (50, 150), color, thickness)   # ç«–çº¿
        
        return img
    
    def rotate_image(self, image, angle):
        """æ—‹è½¬å›¾åƒ"""
        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        
        # è·å–æ—‹è½¬çŸ©é˜µ
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        
        # æ‰§è¡Œæ—‹è½¬
        rotated = cv2.warpAffine(image, rotation_matrix, (width, height))
        return rotated
    
    def calculate_vision_level(self):
        """è®¡ç®—è§†åŠ›æ°´å¹³"""
        if self.total_count == 0:
            return 5.0
        
        accuracy = self.correct_count / self.total_count
        size_ratio = self.current_size
        
        # æ ¹æ®å‡†ç¡®ç‡å’Œå¤§å°ä¼°ç®—è§†åŠ›
        if accuracy > 0.8:
            if size_ratio < 0.2:
                return 5.8
            elif size_ratio < 0.3:
                return 5.6
            elif size_ratio < 0.4:
                return 5.4
            elif size_ratio < 0.5:
                return 5.2
            else:
                return 5.0
        elif accuracy > 0.6:
            return 4.8
        else:
            return 4.5
    
    def calculate_result(self):
        """è®¡ç®—æœ€ç»ˆç»“æœ"""
        if self.total_count == 0:
            return
        
        accuracy = self.correct_count / self.total_count
        vision_level = self.calculate_vision_level()
        
        # ç”Ÿæˆç»“æœæ–‡æœ¬
        result_text = f"æ£€æµ‹å®Œæˆï¼\n"
        result_text += f"è§†åŠ›æ°´å¹³: {vision_level:.1f}\n"
        result_text += f"å‡†ç¡®ç‡: {accuracy:.1%}\n"
        result_text += f"æµ‹è¯•æ¬¡æ•°: {self.total_count}\n"
        result_text += f"å¹³å‡è·ç¦»: {self.distance:.0f}cm"
        
        # è¯„ä¼°è§†åŠ›çŠ¶å†µ
        if vision_level >= 5.0:
            result_text += "\n\nè§†åŠ›çŠ¶å†µ: ä¼˜ç§€"
        elif vision_level >= 4.5:
            result_text += "\n\nè§†åŠ›çŠ¶å†µ: è‰¯å¥½"
        elif vision_level >= 4.0:
            result_text += "\n\nè§†åŠ›çŠ¶å†µ: ä¸€èˆ¬"
        else:
            result_text += "\n\nè§†åŠ›çŠ¶å†µ: éœ€è¦å…³æ³¨"
        
        self.result_label.config(text=result_text)
        self.result = {
            'vision_level': vision_level,
            'accuracy': accuracy,
            'total_count': self.total_count,
            'distance': self.distance,
            'timestamp': time.time()
        }
    
    def close_window(self):
        """å…³é—­çª—å£"""
        self.testing = False
        if self.cap:
            self.cap.release()
        if self.face_mesh:
            self.face_mesh.close()
        if self.hands:
            self.hands.close()
        if self.window:
            self.window.destroy()


class VisionTestTool(BaseTool):
    """è§†åŠ›æ£€æµ‹å·¥å…·"""
    
    name: str = "vision_test"
    description: str = "è¿›è¡ŒåŸºç¡€è§†åŠ›æ£€æµ‹ï¼Œä½¿ç”¨Eå­—è¡¨æµ‹è¯•è§†åŠ›æ°´å¹³"
    test_window: Optional[VisionTestWindow] = None
    
    parameters: Dict[str, Any] = {
        "type": "object",
        "properties": {},
        "required": []
    }
    
    def __init__(self):
        super().__init__()
        self.tkinter_thread = None
        self.root = None
        # å»¶è¿Ÿå¯åŠ¨tkinterä¸»å¾ªç¯çº¿ç¨‹
        self._start_tkinter_thread()
    
    def _start_tkinter_thread(self):
        """åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨tkinterä¸»å¾ªç¯"""
        import threading
        
        def tkinter_mainloop():
            try:
                # åˆ›å»ºéšè—çš„æ ¹çª—å£
                self.root = tk.Tk()
                self.root.withdraw()  # éšè—æ ¹çª—å£
                self.root.mainloop()
            except Exception as e:
                print(f"Tkinterä¸»å¾ªç¯å¯åŠ¨å¤±è´¥: {e}")
        
        # å¯åŠ¨tkinterçº¿ç¨‹
        self.tkinter_thread = threading.Thread(target=tkinter_mainloop, daemon=True)
        self.tkinter_thread.start()
    
    async def execute(self, **kwargs) -> str:
        """æ‰§è¡Œè§†åŠ›æ£€æµ‹"""
        try:
            # ç¡®ä¿tkinterçº¿ç¨‹å·²å¯åŠ¨
            if self.tkinter_thread and not self.tkinter_thread.is_alive():
                self._start_tkinter_thread()
                await asyncio.sleep(0.5)  # ç­‰å¾…çº¿ç¨‹å¯åŠ¨
            
            # åˆ›å»ºæ£€æµ‹çª—å£
            self.test_window = VisionTestWindow()
            self.test_window.create_window()
            
            # ç­‰å¾…æ£€æµ‹å®Œæˆ
            while self.test_window.window and self.test_window.window.winfo_exists():
                await asyncio.sleep(0.1)
            
            # è¿”å›ç»“æœ
            if self.test_window.result:
                result = self.test_window.result
                return f"è§†åŠ›æ£€æµ‹å®Œæˆï¼\nè§†åŠ›æ°´å¹³: {result['vision_level']:.1f}\nå‡†ç¡®ç‡: {result['accuracy']:.1%}\næµ‹è¯•æ¬¡æ•°: {result['total_count']}"
            else:
                return "è§†åŠ›æ£€æµ‹æœªå®Œæˆ"
                
        except Exception as e:
            return f"è§†åŠ›æ£€æµ‹å‡ºé”™: {str(e)}"
        finally:
            if self.test_window:
                self.test_window = None
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # å…³é—­æ£€æµ‹çª—å£
            if self.test_window:
                self.test_window.close_window()
                self.test_window = None
            
            # å…³é—­tkinterä¸»å¾ªç¯
            if self.root:
                self.root.quit()
                self.root.destroy()
        except Exception as e:
            print(f"æ¸…ç†è§†åŠ›æ£€æµ‹èµ„æºå¤±è´¥ï¼š{e}") 